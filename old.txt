#normalized 
#data["Agen"]=data["Agen"]/ data["Agen"].max()
#data["Fare"]=data["Fare"]/ data["Fare"].max()

#data.Survived.value_counts()
#data["Fsize"] = data["SibSp"] + data["Parch"] + 1
#data.groupby('Survived').mean() # Age data has Not a Number 
#data.loc[(data['Fsize']>7), 'F_size']=7
#import matplotlib.pyplot as plt
#def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,
#                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):
#    """Generate a simple plot of the test and training learning curve"""
#    plt.figure()
#    plt.title(title)
#    if ylim is not None:
#        plt.ylim(*ylim)
'''    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
#    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
#             label="Training score")
#    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
#             label="Cross-validation score")

#    plt.legend(loc="best")
#    return plt

'''
#g = plot_learning_curve(svm,"SVC learning curves",X_train,Y_train,cv=kfold)


#null_columns=data.columns[data.Age_group.isnull().any()]
#print(data[data["Age_group"].isnull()])

#data.head()
#data["Pclass"] = data["Pclass"].astype("category")
#data = pd.get_dummies(data, columns = ["Pclass"],prefix="Pc")